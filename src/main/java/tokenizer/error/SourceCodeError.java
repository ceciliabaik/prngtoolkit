// package tokenizer.error;

// public class SourceCodeError {

//     public void throwErrorIllegalCharacters() {
//     }

//     public void lexicalError() {}
// }

  // public void addToEnumMapRegex() {
  //   RegexPattern<TokenTypes, String> regexPatterns = new EnumMap<>(TokenTypes.class);
  //   regexPatterns.put(TokenTypes.WORD, regexPatterns.literalCharClass());
  //   System.out.println("Regex patterns" + regexPatterns);
  // }
